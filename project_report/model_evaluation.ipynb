{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import pipeline, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paradigms in the BLiMP dataset\n",
    "paradigms = ['adjunct_island', \n",
    "             'anaphor_gender_agreement', \n",
    "             'anaphor_number_agreement', \n",
    "             'animate_subject_passive', \n",
    "             'animate_subject_trans', \n",
    "             'causative', \n",
    "             'complex_NP_island', \n",
    "             'coordinate_structure_constraint_complex_left_branch', \n",
    "             'coordinate_structure_constraint_object_extraction', \n",
    "             'determiner_noun_agreement_1', \n",
    "             'determiner_noun_agreement_2', \n",
    "             'determiner_noun_agreement_irregular_1', \n",
    "             'determiner_noun_agreement_irregular_2', \n",
    "             'determiner_noun_agreement_with_adj_2', \n",
    "             'determiner_noun_agreement_with_adj_irregular_1', \n",
    "             'determiner_noun_agreement_with_adj_irregular_2', \n",
    "             'determiner_noun_agreement_with_adjective_1', \n",
    "             'distractor_agreement_relational_noun', \n",
    "             'distractor_agreement_relative_clause', \n",
    "             'drop_argument', \n",
    "             'ellipsis_n_bar_1', \n",
    "             'ellipsis_n_bar_2', \n",
    "             'existential_there_object_raising', \n",
    "             'existential_there_quantifiers_1', \n",
    "             'existential_there_quantifiers_2', \n",
    "             'existential_there_subject_raising', \n",
    "             'expletive_it_object_raising', \n",
    "             'inchoative', \n",
    "             'intransitive', \n",
    "             'irregular_past_participle_adjectives', \n",
    "             'irregular_past_participle_verbs', \n",
    "             'irregular_plural_subject_verb_agreement_1', \n",
    "             'irregular_plural_subject_verb_agreement_2', \n",
    "             'left_branch_island_echo_question', \n",
    "             'left_branch_island_simple_question', \n",
    "             #'matrix_question_npi_licensor_present', \n",
    "             'npi_present_1', \n",
    "             'npi_present_2', \n",
    "             'only_npi_licensor_present',\n",
    "             'only_npi_scope', \n",
    "             'passive_1', \n",
    "             'passive_2', \n",
    "             'principle_A_c_command', \n",
    "             'principle_A_case_1', \n",
    "             'principle_A_case_2', \n",
    "             'principle_A_domain_1', \n",
    "             'principle_A_domain_2', \n",
    "             'principle_A_domain_3', \n",
    "             'principle_A_reconstruction', \n",
    "             'regular_plural_subject_verb_agreement_1', \n",
    "             'regular_plural_subject_verb_agreement_2', \n",
    "             'sentential_negation_npi_licensor_present', \n",
    "             'sentential_negation_npi_scope', \n",
    "             'sentential_subject_island', \n",
    "             'superlative_quantifiers_1', \n",
    "             'superlative_quantifiers_2', \n",
    "             'tough_vs_raising_1', \n",
    "             'tough_vs_raising_2', \n",
    "             'transitive', \n",
    "             'wh_island', \n",
    "             'wh_questions_object_gap', \n",
    "             'wh_questions_subject_gap', \n",
    "             'wh_questions_subject_gap_long_distance', \n",
    "             'wh_vs_that_no_gap', \n",
    "             'wh_vs_that_no_gap_long_distance', \n",
    "             'wh_vs_that_with_gap', \n",
    "             'wh_vs_that_with_gap_long_distance']\n",
    "\n",
    "# A dictionary with abbveriations of lingustic terms for better display\n",
    "phenomena = {\n",
    "        \"anaphor_agreement\": \"ANA AGR\",\n",
    "        \"argument_structure\": \"ARG STR\",\n",
    "        \"binding\": \"BINDING\",\n",
    "        \"control_raising\": \"CTRL RAIS\",\n",
    "        \"determiner_noun_agreement\": \"D-N AGR\",\n",
    "        \"ellipsis\": \"ELLIPSIS\",\n",
    "        \"filler_gap_dependency\": \"FILLER. GAP\",\n",
    "        \"irregular_forms\": \"IRREGULAR\",\n",
    "        \"island_effects\": \"ISLAND\",\n",
    "        \"npi_licensing\": \"NPI\",\n",
    "        \"quantifiers\": \"QUANTIFIERS\",\n",
    "        \"subject_verb_agreement\": \"S-V AGR\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wh_vs_that_with_gap_long_distance: 100.00%                                               "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_good</th>\n",
       "      <th>sentence_bad</th>\n",
       "      <th>field</th>\n",
       "      <th>linguistics_term</th>\n",
       "      <th>paradigm</th>\n",
       "      <th>simple_LM_method</th>\n",
       "      <th>one_prefix_method</th>\n",
       "      <th>two_prefix_method</th>\n",
       "      <th>lexically_identical</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>phenomenon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who should Derek hug after shocking Richard?</td>\n",
       "      <td>Who should Derek hug Richard after shocking?</td>\n",
       "      <td>syntax</td>\n",
       "      <td>island_effects</td>\n",
       "      <td>adjunct_island</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>ISLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What had Theresa walked through while talking ...</td>\n",
       "      <td>What had Theresa walked through that high scho...</td>\n",
       "      <td>syntax</td>\n",
       "      <td>island_effects</td>\n",
       "      <td>adjunct_island</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>ISLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who will Katherine discover without hiring Erin?</td>\n",
       "      <td>Who will Katherine discover Erin without hiring?</td>\n",
       "      <td>syntax</td>\n",
       "      <td>island_effects</td>\n",
       "      <td>adjunct_island</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>ISLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who has Colleen aggravated before kissing Judy?</td>\n",
       "      <td>Who has Colleen aggravated Judy before kissing?</td>\n",
       "      <td>syntax</td>\n",
       "      <td>island_effects</td>\n",
       "      <td>adjunct_island</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>ISLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What could a lot of cats break while finding a...</td>\n",
       "      <td>What could a lot of cats break all convertible...</td>\n",
       "      <td>syntax</td>\n",
       "      <td>island_effects</td>\n",
       "      <td>adjunct_island</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "      <td>ISLAND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       sentence_good  \\\n",
       "0       Who should Derek hug after shocking Richard?   \n",
       "1  What had Theresa walked through while talking ...   \n",
       "2   Who will Katherine discover without hiring Erin?   \n",
       "3    Who has Colleen aggravated before kissing Judy?   \n",
       "4  What could a lot of cats break while finding a...   \n",
       "\n",
       "                                        sentence_bad   field linguistics_term  \\\n",
       "0       Who should Derek hug Richard after shocking?  syntax   island_effects   \n",
       "1  What had Theresa walked through that high scho...  syntax   island_effects   \n",
       "2   Who will Katherine discover Erin without hiring?  syntax   island_effects   \n",
       "3    Who has Colleen aggravated Judy before kissing?  syntax   island_effects   \n",
       "4  What could a lot of cats break all convertible...  syntax   island_effects   \n",
       "\n",
       "         paradigm  simple_LM_method  one_prefix_method  two_prefix_method  \\\n",
       "0  adjunct_island              True              False              False   \n",
       "1  adjunct_island              True              False              False   \n",
       "2  adjunct_island              True              False              False   \n",
       "3  adjunct_island              True              False              False   \n",
       "4  adjunct_island              True              False              False   \n",
       "\n",
       "   lexically_identical  pair_id phenomenon  \n",
       "0                 True        0     ISLAND  \n",
       "1                 True        1     ISLAND  \n",
       "2                 True        2     ISLAND  \n",
       "3                 True        3     ISLAND  \n",
       "4                 True        4     ISLAND  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe to hold data for each paradigm\n",
    "blimp_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each paradigm and filter the dataset\n",
    "for paradigm in paradigms:\n",
    "    # Load the dataset for the current paradigm\n",
    "    subset = load_dataset('nyu-mll/BLiMP', name=paradigm)\n",
    "    \n",
    "    # Convert the dataset to a dataframe and add the paradigm column\n",
    "    subset_df = pd.DataFrame(subset['train'])\n",
    "    subset_df.rename(columns={'UID': 'paradigm'}, inplace=True)\n",
    "    # Add the phenomenon column using the phenomena dictionary\n",
    "    subset_df['phenomenon'] = subset_df['linguistics_term'].map(phenomena).fillna('EMPTY')\n",
    "\n",
    "    # Print loading status\n",
    "    print(f\"\\rLoading {paradigm}: {((paradigms.index(paradigm) + 1) / len(paradigms)) * 100:.2f}%{' ' * 30}\", end='')\n",
    "    \n",
    "    # Append the subset dataframe to the main dataframe\n",
    "    blimp_df = pd.concat([blimp_df, subset_df], ignore_index=True)\n",
    "\n",
    "# Display the combined dataframe\n",
    "blimp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identical sentences: 7\n",
      "Details of identical sentences:\n",
      "                                           sentence_good            paradigm\n",
      "39324               Douglas's senator was left by Susan.           passive_1\n",
      "39810  Some grandmother of the cashier was left by Ja...           passive_1\n",
      "43105  Mark hadn't forgotten about himself skated aro...  principle_A_case_2\n",
      "43287  Leslie imagined herself skated around the hosp...  principle_A_case_2\n",
      "43372  Susan thinks about herself skated around a river.  principle_A_case_2\n",
      "43816  Amanda had imagined herself skated around a lo...  principle_A_case_2\n",
      "43967  The cashiers think about themselves skated aro...  principle_A_case_2\n"
     ]
    }
   ],
   "source": [
    "# Filter entries where sentence_good is equal to sentence_bad\n",
    "identical_sentences = blimp_df[blimp_df['sentence_good'] == blimp_df['sentence_bad']]\n",
    "\n",
    "# Print a report\n",
    "print(f\"Number of identical sentences: {len(identical_sentences)}\")\n",
    "if not identical_sentences.empty:\n",
    "    print(\"Details of identical sentences:\")\n",
    "    print(identical_sentences[['sentence_good', 'paradigm']])\n",
    "else:\n",
    "    print(\"No identical sentences found.\")\n",
    "\n",
    "# Drop identical sentences from the dataframe\n",
    "blimp_df = blimp_df[blimp_df['sentence_good'] != blimp_df['sentence_bad']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BERT tokenizer\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# Function to create a masked sentence with shared tokens and a single [MASK] for differences\n",
    "def process_tokens(row):\n",
    "    # Tokenize the good and bad sentences\n",
    "    good_tokens = row['sentence_good'].split()\n",
    "    bad_tokens = row['sentence_bad'].split()\n",
    "\n",
    "    # Remove common tokens from the beginning\n",
    "    common_start = []\n",
    "    while good_tokens and bad_tokens and good_tokens[0] == bad_tokens[0]:\n",
    "        common_start.append(good_tokens.pop(0))\n",
    "        bad_tokens.pop(0)\n",
    "\n",
    "    # Remove common tokens from the end\n",
    "    common_end = []\n",
    "    while good_tokens and bad_tokens and good_tokens[-1] == bad_tokens[-1]:\n",
    "        common_end.insert(0, good_tokens.pop(-1))\n",
    "        bad_tokens.pop(-1)\n",
    "\n",
    "\n",
    "    # If the good or bad tokens are empty, add a common token to both\n",
    "    if good_tokens == [] or bad_tokens == []:\n",
    "        additional_tokens = common_end.pop(0)\n",
    "        print(\"additional token:\", additional_tokens)\n",
    "        good_tokens.append(additional_tokens)\n",
    "        bad_tokens.append(additional_tokens)\n",
    "\n",
    "    # Collect the remaining tokens as the masked sentence\n",
    "    common_tokens = common_start + [\"[MASK]\"] + common_end\n",
    "    \n",
    "    good_fillers = bert_tokenizer.tokenize(\" \".join(good_tokens))\n",
    "    bad_fillers = bert_tokenizer.tokenize(\" \".join(bad_tokens))\n",
    "\n",
    "    sentence_masked = \" \".join(common_tokens)\n",
    "\n",
    "    # If the last token of the good and bad fillers is the same, add it to the masked sentence (same punctuation with MASK at the end)\n",
    "    if len(good_fillers) > 1 and len(bad_fillers) > 1: \n",
    "        if good_fillers[-1] == bad_fillers[-1]:\n",
    "            remove_punct = good_fillers.pop(-1)\n",
    "            sentence_masked += remove_punct\n",
    "            bad_fillers.pop(-1)\n",
    "\n",
    "    return sentence_masked, good_fillers, bad_fillers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to the DataFrame\n",
    "blimp_df[['sentence_masked', 'good_fillers', 'bad_fillers']] = blimp_df.apply(lambda row: pd.Series(process_tokens(row)), axis=1)\n",
    "\n",
    "# Display a sample of the updated DataFrame\n",
    "blimp_df[['sentence_masked', 'good_fillers', 'bad_fillers']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_good</th>\n",
       "      <th>sentence_bad</th>\n",
       "      <th>field</th>\n",
       "      <th>linguistics_term</th>\n",
       "      <th>paradigm</th>\n",
       "      <th>simple_LM_method</th>\n",
       "      <th>one_prefix_method</th>\n",
       "      <th>two_prefix_method</th>\n",
       "      <th>lexically_identical</th>\n",
       "      <th>pair_id</th>\n",
       "      <th>phenomenon</th>\n",
       "      <th>sentence_masked</th>\n",
       "      <th>good_fillers</th>\n",
       "      <th>bad_fillers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39403</th>\n",
       "      <td>All guys were talked about by a lot of libraries.</td>\n",
       "      <td>All guys were talked by a lot of libraries.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>argument_structure</td>\n",
       "      <td>passive_1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>403</td>\n",
       "      <td>ARG STR</td>\n",
       "      <td>All guys were talked [MASK] by a lot of librar...</td>\n",
       "      <td>[about]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57607</th>\n",
       "      <td>Samuel would escape from a waitress.</td>\n",
       "      <td>Samuel would escape a waitress.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>argument_structure</td>\n",
       "      <td>transitive</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>607</td>\n",
       "      <td>ARG STR</td>\n",
       "      <td>Samuel would escape [MASK] a waitress.a</td>\n",
       "      <td>[from]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57944</th>\n",
       "      <td>The story hadn't disagreed with these actresses.</td>\n",
       "      <td>The story hadn't disagreed these actresses.</td>\n",
       "      <td>syntax</td>\n",
       "      <td>argument_structure</td>\n",
       "      <td>transitive</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>944</td>\n",
       "      <td>ARG STR</td>\n",
       "      <td>The story hadn't disagreed [MASK] these actres...</td>\n",
       "      <td>[with]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence_good  \\\n",
       "39403  All guys were talked about by a lot of libraries.   \n",
       "57607               Samuel would escape from a waitress.   \n",
       "57944   The story hadn't disagreed with these actresses.   \n",
       "\n",
       "                                      sentence_bad   field  \\\n",
       "39403  All guys were talked by a lot of libraries.  syntax   \n",
       "57607              Samuel would escape a waitress.  syntax   \n",
       "57944  The story hadn't disagreed these actresses.  syntax   \n",
       "\n",
       "         linguistics_term    paradigm  simple_LM_method  one_prefix_method  \\\n",
       "39403  argument_structure   passive_1              True              False   \n",
       "57607  argument_structure  transitive              True              False   \n",
       "57944  argument_structure  transitive              True              False   \n",
       "\n",
       "       two_prefix_method  lexically_identical  pair_id phenomenon  \\\n",
       "39403              False                False      403    ARG STR   \n",
       "57607               True                False      607    ARG STR   \n",
       "57944               True                False      944    ARG STR   \n",
       "\n",
       "                                         sentence_masked good_fillers  \\\n",
       "39403  All guys were talked [MASK] by a lot of librar...      [about]   \n",
       "57607            Samuel would escape [MASK] a waitress.a       [from]   \n",
       "57944  The story hadn't disagreed [MASK] these actres...       [with]   \n",
       "\n",
       "      bad_fillers  \n",
       "39403          []  \n",
       "57607          []  \n",
       "57944          []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filter rows where good_fillers or bad_fillers are empty\n",
    "empty_fillers = blimp_df[(blimp_df['good_fillers'].apply(len) == 0) | (blimp_df['bad_fillers'].apply(len) == 0)]\n",
    "\n",
    "# Print the filtered rows\n",
    "display(empty_fillers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply the probabilities of the fillers to get the probability of the full sentence\n",
    "def get_filler_probability(model, sentence, filler):\n",
    "    total_probability = 1\n",
    "\n",
    "    # Iterate over the fillers and calculate the probability of each word\n",
    "    for i in range(0, len(filler)):\n",
    "        word = filler[i]\n",
    "        next_word = filler[i+1] if i+1 < len(filler) else \"\"\n",
    "\n",
    "        # Calculate the probability of the current word\n",
    "        word_probability = model(sentence, targets=[word])[0]['score']\n",
    "        total_probability *= word_probability\n",
    "\n",
    "        # Update the sentence with the filled word, pay attention to the ## tokens\n",
    "        if word.startswith(\"##\"):\n",
    "            if next_word.startswith('##'):\n",
    "                sentence = sentence.replace(\"[MASK]\", word[2:] + \"[MASK]\")\n",
    "            else:\n",
    "                sentence = sentence.replace(\"[MASK]\", word[2:] + \" [MASK]\")\n",
    "        else:\n",
    "            if next_word.startswith('##'):\n",
    "                sentence = sentence.replace(\"[MASK]\", word + \"[MASK]\")\n",
    "            else:\n",
    "                sentence = sentence.replace(\"[MASK]\", word + \" [MASK]\")\n",
    "\n",
    "        # Remove the [MASK] token if it is the last word\n",
    "        if i+1 == len(filler):\n",
    "            sentence = sentence.replace(\" [MASK]\", \"\")\n",
    "\n",
    "    return total_probability ** (1 / len(filler)) if len(filler) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_masked</th>\n",
       "      <th>good_fillers</th>\n",
       "      <th>bad_fillers</th>\n",
       "      <th>bert_good_prob</th>\n",
       "      <th>bert_bad_prob</th>\n",
       "      <th>bert_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who should Derek hug [MASK]?</td>\n",
       "      <td>[after, shocking, Richard]</td>\n",
       "      <td>[Richard, after, shocking]</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What had Theresa walked through [MASK]?</td>\n",
       "      <td>[while, talking, about, that, high, school]</td>\n",
       "      <td>[that, high, school, while, talking, about]</td>\n",
       "      <td>0.009957</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who will Katherine discover [MASK]?</td>\n",
       "      <td>[without, hiring, Erin]</td>\n",
       "      <td>[Erin, without, hiring]</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who has Colleen aggravated [MASK]?</td>\n",
       "      <td>[before, kissing, Judy]</td>\n",
       "      <td>[Judy, before, kissing]</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What could a lot of cats break [MASK]?</td>\n",
       "      <td>[while, finding, all, convertible, ##s]</td>\n",
       "      <td>[all, convertible, ##s, while, finding]</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65995</th>\n",
       "      <td>A lot of boys remember [MASK] a report that di...</td>\n",
       "      <td>[what]</td>\n",
       "      <td>[that]</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.005557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65996</th>\n",
       "      <td>Some committees knew [MASK] the actresses that...</td>\n",
       "      <td>[who]</td>\n",
       "      <td>[that]</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65997</th>\n",
       "      <td>All governments forgot [MASK] these deer that ...</td>\n",
       "      <td>[what]</td>\n",
       "      <td>[that]</td>\n",
       "      <td>0.138488</td>\n",
       "      <td>0.314943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65998</th>\n",
       "      <td>Every patient didn't remember [MASK] these wai...</td>\n",
       "      <td>[who]</td>\n",
       "      <td>[that]</td>\n",
       "      <td>0.025648</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65999</th>\n",
       "      <td>This company was discovering [MASK] some libra...</td>\n",
       "      <td>[who]</td>\n",
       "      <td>[that]</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.073401</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65993 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sentence_masked  \\\n",
       "0                           Who should Derek hug [MASK]?   \n",
       "1                What had Theresa walked through [MASK]?   \n",
       "2                    Who will Katherine discover [MASK]?   \n",
       "3                     Who has Colleen aggravated [MASK]?   \n",
       "4                 What could a lot of cats break [MASK]?   \n",
       "...                                                  ...   \n",
       "65995  A lot of boys remember [MASK] a report that di...   \n",
       "65996  Some committees knew [MASK] the actresses that...   \n",
       "65997  All governments forgot [MASK] these deer that ...   \n",
       "65998  Every patient didn't remember [MASK] these wai...   \n",
       "65999  This company was discovering [MASK] some libra...   \n",
       "\n",
       "                                      good_fillers  \\\n",
       "0                       [after, shocking, Richard]   \n",
       "1      [while, talking, about, that, high, school]   \n",
       "2                          [without, hiring, Erin]   \n",
       "3                          [before, kissing, Judy]   \n",
       "4          [while, finding, all, convertible, ##s]   \n",
       "...                                            ...   \n",
       "65995                                       [what]   \n",
       "65996                                        [who]   \n",
       "65997                                       [what]   \n",
       "65998                                        [who]   \n",
       "65999                                        [who]   \n",
       "\n",
       "                                       bad_fillers  bert_good_prob  \\\n",
       "0                       [Richard, after, shocking]        0.000078   \n",
       "1      [that, high, school, while, talking, about]        0.009957   \n",
       "2                          [Erin, without, hiring]        0.000013   \n",
       "3                          [Judy, before, kissing]        0.000265   \n",
       "4          [all, convertible, ##s, while, finding]        0.000062   \n",
       "...                                            ...             ...   \n",
       "65995                                       [that]        0.000803   \n",
       "65996                                       [that]        0.000485   \n",
       "65997                                       [that]        0.138488   \n",
       "65998                                       [that]        0.025648   \n",
       "65999                                       [that]        0.000619   \n",
       "\n",
       "       bert_bad_prob  bert_prediction  \n",
       "0           0.000024                1  \n",
       "1           0.005844                1  \n",
       "2           0.000009                1  \n",
       "3           0.000082                1  \n",
       "4           0.000051                1  \n",
       "...              ...              ...  \n",
       "65995       0.005557                0  \n",
       "65996       0.005854                0  \n",
       "65997       0.314943                0  \n",
       "65998       0.014695                1  \n",
       "65999       0.073401                0  \n",
       "\n",
       "[65993 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_cased = pipeline(\"fill-mask\", model=\"bert-base-cased\")\n",
    "#mbert_cased = pipeline(\"fill-mask\", model=\"bert-base-multilingual-cased\")\n",
    "\n",
    "# different tokenizer needs different handling\n",
    "#bibert_cased = pipeline(\"fill-mask\", model=\"jhu-clsp/bibert-ende\", tokenizer=BertTokenizer.from_pretrained(\"jhu-clsp/bibert-ende\"))\n",
    "\n",
    "\n",
    "# deploy_df = blimp_df.sample(1000)\n",
    "deploy_df = blimp_df.copy()\n",
    "\n",
    "# Calculate the probabilities for the good and bad fillers\n",
    "deploy_df['bert_good_prob'] = deploy_df.apply(\n",
    "    lambda row: get_filler_probability(bert_cased, row['sentence_masked'], row['good_fillers']), axis=1\n",
    ")\n",
    "deploy_df['bert_bad_prob'] = deploy_df.apply(\n",
    "    lambda row: get_filler_probability(bert_cased, row['sentence_masked'], row['bad_fillers']), axis=1\n",
    ")\n",
    "\n",
    "# Calculate the prediction based on the probabilities\n",
    "deploy_df['bert_prediction'] = deploy_df.apply(\n",
    "    lambda row: 1 if row['bert_good_prob'] > row['bert_bad_prob'] else 0, axis=1\n",
    ")\n",
    "\n",
    "display(deploy_df[['sentence_masked', 'good_fillers', 'bad_fillers', 'bert_good_prob', 'bert_bad_prob', 'bert_prediction']])\n",
    "deploy_df['bert_prediction'].value_counts()\n",
    "\n",
    "# Save the dataframe to a CSV file\n",
    "deploy_df.to_csv(\"bert_base_cased_prediction.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
